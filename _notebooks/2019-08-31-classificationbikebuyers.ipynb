{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset \n",
    "customer_info = pd.read_csv('Data/AdvWorksCusts.csv')\n",
    "customer_spending = pd.read_csv('Data/AW_AveMonthSpend.csv')\n",
    "customer_has_bike = pd.read_csv('Data/AW_BikeBuyer.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are any ? in the data \n",
    "(customer_info.astype(np.object) == '?').any()\n",
    "(customer_spending.astype(np.object) == '?').any()\n",
    "(customer_has_bike.astype(np.object) == '?').any()\n",
    "# checking for missing values \n",
    "print((customer_info.astype(np.object).isnull()).any())\n",
    "print((customer_spending.astype(np.object).isnull()).any())\n",
    "print((customer_has_bike.astype(np.object).isnull()).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicate \n",
    "print( \"Customer data\")\n",
    "print(customer_info.shape)\n",
    "print(customer_info.CustomerID.unique().shape)\n",
    "\n",
    "print('\\n' + \"Customer Spending \")\n",
    "print(customer_spending.shape)\n",
    "print(customer_spending.CustomerID.unique().shape)\n",
    "\n",
    "print('\\n' + \"Customer has bikes\")\n",
    "print(customer_has_bike.shape)\n",
    "print(customer_has_bike.CustomerID.unique().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing duplicate \n",
    "customer_info.drop_duplicates(subset='CustomerID', keep='last',inplace=True)\n",
    "print(customer_info.shape)\n",
    "print(customer_info.CustomerID.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_spending.drop_duplicates(subset='CustomerID',keep='last',inplace=True)\n",
    "print(customer_spending.shape)\n",
    "print(customer_spending.CustomerID.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_has_bike.drop_duplicates(subset='CustomerID',keep='last',inplace=True)\n",
    "print(customer_has_bike.shape)\n",
    "print(customer_has_bike.CustomerID.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical information for customer_info datasets \n",
    "customer_info.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical information for customer_spending datasets \n",
    "customer_has_bike.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retuning the count in Bikebuyer in each category\n",
    "#normalize to retun the relative frequency\n",
    "print(customer_has_bike.BikeBuyer.value_counts(normalize=True))\n",
    "print(customer_has_bike.BikeBuyer.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging customer_info and customer_has_bike \n",
    "combined = customer_info.merge(customer_has_bike,\n",
    "                              on = 'CustomerID',\n",
    "                              how='left')\n",
    "combined.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Running various visualization to see features to select for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define func.for plotting box plot \n",
    "def plot_box(combined, cols, col_x= 'BikeBuyer'):\n",
    "    for col in cols:\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.boxplot(col_x, col, data=combined)\n",
    "        plt.xlabel(col_x) # set x-axis\n",
    "        plt.ylabel(col) # set y-axis \n",
    "        plt.show()\n",
    "cols =['YearlyIncome','NumberCarsOwned'\n",
    "       ,'NumberChildrenAtHome','TotalChildren']\n",
    "plot_box(combined, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bar plot to analyse categorical variables \n",
    "# forming categorical variables \n",
    "\n",
    "is_bike_buyer = combined.BikeBuyer== 1 \n",
    "bike_buyers = combined[is_bike_buyer]\n",
    "is_non_bike_buyer = combined.BikeBuyer == 0\n",
    "non_bike_buyers = combined[is_non_bike_buyer]\n",
    "\n",
    "print(bike_buyers.shape)\n",
    "print(non_bike_buyers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot func. for non numeric features \n",
    "# plot bar plot bike buyers counts \n",
    "\n",
    "def plot_bar(cat_cols):\n",
    "    combined['dummy'] = np.ones(shape = combined.shape[0])\n",
    "    for col in cat_cols:\n",
    "        counts = combined[['dummy','BikeBuyer', col]].groupby(['BikeBuyer',col],\n",
    "                                                            as_index = False).count()\n",
    "        temp = counts[counts['BikeBuyer'] ==0][[col,'dummy']]\n",
    "        temp.plot.bar(x=col, y= 'dummy')\n",
    "        \n",
    "        plt.title('Counts for ' + col + '\\n non bike buyer') \n",
    "        plt.ylabel('count')\n",
    "        temp = counts[counts['BikeBuyer'] == 1][[col,'dummy']]\n",
    "        temp.plot.bar(x=col, y='dummy')\n",
    "        \n",
    "        plt.title('Counts for ' + col + '\\n bike buyer') \n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Occupation','Gender','MaritalStatus']\n",
    "plot_bar(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try feature generation - hasChildren \n",
    "has_child_at_home = [] \n",
    "def generate_has_child_at_home(customer_info, has_child_at_home):\n",
    "    for index, row in customer_info.iterrows():\n",
    "        if row.NumberChildrenAtHome>0:\n",
    "            has_child_at_home.append('Y')\n",
    "        else:\n",
    "            has_child_at_home.append('N')\n",
    "    return has_child_at_home\n",
    "combined['hasChildAtHome'] = generate_has_child_at_home(customer_info, has_child_at_home)\n",
    "combined[['hasChildAtHome','NumberChildrenAtHome']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating age\n",
    "from datetime import datetime \n",
    "from dateutil.parser import parse\n",
    "\n",
    "def generate_age(data, format):\n",
    "    collect_date = birthday = datetime(1998,1,1,0,0,0)\n",
    "    age = [] \n",
    "    for index, row in data.iterrows():\n",
    "        cust_date = datetime.strptime(row['BirthDate'], format)\n",
    "        age.append(int((collect_date - cust_date).days/365))\n",
    "    return age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = generate_age(data, '%Y-%m-%d')\n",
    "data[['BirthDate','Age']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['hasChildAtHome']\n",
    "plot_bar(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_chosen = ['YearlyIncome','NumberCarsOwned','Occupation','Gender','MaritalStatus',\n",
    "                  'hasChildAtHome']\n",
    "features = combined[features_chosen]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data for scikit learn\n",
    "    1. encode categorical variable using one hot encoding. \n",
    "    2. convert features and labels to numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(combined.BikeBuyer)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(cat_features):\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat_features(features):\n",
    "    cat_features = ['Gender','MaritalStatus','hasChildAtHome']\n",
    "    f = encode_string(features['Occupation']) \n",
    "    for cat in cat_features:\n",
    "        enc = encode_string(features[cat])\n",
    "        f = np.concatenate([f, enc], 1)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = np.array(combined[['YearlyIncome','NumberCarsOwned']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = encode_cat_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate([encoded_features,numeric_features],1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#picking 3rd row and all columnsi.e. upto 13 columns\n",
    "features[3,:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spilting data into train and test sets \n",
    "\n",
    "nr.seed(9988)\n",
    "indx = range(features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size=300)\n",
    "X_train = features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "X_test = features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select row 0 to 1 from X_train\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to scale, this would be useful especially for yearly income \n",
    "scalar = preprocessing.MinMaxScaler(feature_range=(-1,1)).fit(X_train[:,11:])\n",
    "X_train[:,11:] = scalar.transform(X_train[:,11:]) \n",
    "X_test[:,11:] = scalar.transform(X_test[:,11:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now features are set and we can move on with logistic regression \n",
    "# Due to class inbalanc for bike buyers and no bike buyer, the class weight parameter is used \n",
    "logistic_mod = linear_model.LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erforming cross validation for regularization parameter C \n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle=True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle=True)\n",
    "nr.seed(3456)\n",
    "param_grid = {\"C\": [0.1,1,10,100,1000]}\n",
    "clf = ms.GridSearchCV(estimator=logistic_mod, param_grid=param_grid,\n",
    "                     cv=inside, # using the inside folds\n",
    "                     scoring = 'roc_auc',\n",
    "                     return_train_score = True) \n",
    "clf.fit(features,labels)\n",
    "clf.best_estimator_.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, features, labels, \n",
    "                                cv = outside) # use the outside folds\n",
    "print('Mean perfomance metic = %4.3f' %np.mean(cv_estimate))\n",
    "print('STD of the metric     = %4.3f' %np.std(cv_estimate))\n",
    "print('Outcome by cv fold')\n",
    "for i, x in enumerate (cv_estimate):\n",
    "    print('Fold %2d      %4.3f' % (i+1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the logistic model to data \n",
    "logistic_mod = linear_model.LogisticRegression(C=clf.best_estimator_.C, class_weight='balanced')\n",
    "logistic_mod.fit(X_train,y_train)\n",
    "print(logistic_mod.intercept_)\n",
    "print(logistic_mod.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = logistic_mod.predict_proba(X_test)\n",
    "print(probabilities[:15,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "threshold = 0.51 \n",
    "scores = score_model(probabilities, threshold) \n",
    "print(np.array(scores[:18]))\n",
    "print(y_test[:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_matrics(y_test, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(labels, probs):\n",
    "    ## compute the false postive rate, true positive rate  and threshold  along with the AUC \n",
    "    fpr, tpr, threshold = sklm.roc_curve(labels, probs[:,1]) \n",
    "    auc = sklm.auc(fpr, tpr)\n",
    "\n",
    "    ## plot the result \n",
    "    plt.title('Reciever Operating Charateristic')\n",
    "    plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' %auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.ylabel('True Positive Rate') \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "plot_auc(y_test, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empolying the Random Forest Classifier \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'max_features': [2,3,5,10,13], 'min_samples_leaf':[3,5,10,20]} \n",
    "nr.seed(3456) \n",
    "rf_clf = RandomForestClassifier(class_weight = 'balanced')\n",
    "nr.seed(4455)\n",
    "rf_clf = ms.GridSearchCV(estimator=rf_clf, param_grid=param_grid,\n",
    "                        cv = inside, # Use the inside folds\n",
    "                        scoring = 'roc_auc', return_train_score = True)\n",
    "rf_clf.fit(features, labels)\n",
    "print(rf_clf.best_estimator_.max_features)\n",
    "print(rf_clf.best_estimator_.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empolying the Random Forest Classifier\n",
    "nr.seed(1115)\n",
    "rf_mod = RandomForestClassifier(class_weight='balanced',\n",
    "                               max_features = rf_clf.best_estimator_.max_features,\n",
    "                               min_samples_leaf =rf_clf.best_estimator_.min_samples_leaf)\n",
    "rf_mod.fit(X_train,y_train)\n",
    "probabilities = rf_mod.predict_proba(X_test)\n",
    "scores = score_model(probabilities,0.54)\n",
    "print(print_matrics(y_test, scores))\n",
    "plot_auc(y_test,probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## empolying the Support Vector Machines, kernel = 'linear'\n",
    "#nr.seed(1115)\n",
    "from sklearn.svm import SVC \n",
    "svclassifier = SVC(kernel='linear',probability=True, random_state= 0)\n",
    "svclassifier.fit(X_train,y_train)\n",
    "probabilities = svclassifier.predict_proba(X_test)\n",
    "scores = score_model(probabilities,0.54)\n",
    "print(print_matrics(y_test, scores))\n",
    "plot_auc(y_test, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunning svm parameters \n",
    "from sklearn.svm import SVC \n",
    "svclassifier = SVC(kernel='linear', random_state=0)\n",
    "svclassifier.fit(X_train,y_train)\n",
    "\n",
    "param_grid = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "\n",
    "\n",
    "svm_clf = ms.GridSearchCV(estimator= svclassifier,\n",
    "                          param_grid= param_grid,\n",
    "                          scoring= 'accuracy',\n",
    "                          cv= 3,\n",
    "                          n_jobs=-1)\n",
    "svm_clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm_clf.best_score_)\n",
    "print(svm_clf.best_params_)\n",
    "print(svm_clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the best gamma value above \n",
    "from sklearn.svm import SVC \n",
    "svclassifier = SVC(kernel='rbf',C=1,probability=True, gamma=0.7)\n",
    "svclassifier.fit(X_train,y_train)\n",
    "probabilities = svclassifier.predict_proba(X_test)\n",
    "scores = score_model(probabilities,0.54)\n",
    "print(print_matrics(y_test, scores))\n",
    "plot_auc(y_test, probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the accuracy of all the models used seems we settle on SVM with the parameters used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import final test data and adding additonal features \n",
    "final = pd.read_csv('Data/AW_test.csv')\n",
    "final['hasChildAtHome'] = generate_has_child_at_home(final,[])\n",
    "final_features = final[features_chosen]\n",
    "\n",
    "numeric_final_features = np.array(final_features[['YearlyIncome','NumberCarsOwned']])\n",
    "\n",
    "encoded_final_features = encode_cat_features(final_features)\n",
    "\n",
    "final_features = np.concatenate([encoded_final_features, numeric_final_features],1)\n",
    "\n",
    "final_features[:,11:] = scalar.transform(final_features[:,11:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = svclassifier.predict_proba(final_features)\n",
    "scores = score_model(probabilities, 0.54)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('final_answer_classification.csv',scores,delimiter=',',fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
